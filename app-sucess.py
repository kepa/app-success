# -*- coding: utf-8 -*-
"""Intro Python - Trabalho.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14x3QqgvCOGEuK8Gkb_g4q74-qoQEAvU5

# Trabalho final - Análise da Play Store: qual será o proxímo grande app?

Dataset extraído de:

* https://www.kaggle.com/datasets/lava18/google-play-store-apps
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import graphviz

from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from lime import lime_tabular

from google.colab import drive

drive.mount('/content/drive')

"""# 1 - Analisando a Estrutura do Dataset

Desenvolver um modelo preditivo para identificar os elementos determinantes do sucesso de um aplicativo em lojas digitais apresenta desafios multifacetados e cruciais. A complexidade reside na vasta gama de variáveis que influenciam a aceitação e o desempenho de um aplicativo, desde características técnicas até preferências do usuário. Compreender como atributos como engajamneto dos usuários, estratégias de monetização e análise de feedback influenciam a popularidade e a adoção de um aplicativo é essencial para construir um modelo preditivo.

O foco deste trabalho é compreender o comportamento real de aplicativos e como levam ao sucesso em lojas dedicadas e tentar determinar elementos quantificáveis que tragam sucesso.
"""

#Extraindo os dados do dataset original e analisando os elementos iniciais
df = pd.read_csv('/content/drive/MyDrive/docs/googleplaystore.csv')
print(df.head())

#Análise da estrutura dos dados
print(df.info())
print(df.describe())

"""As variáveis do data sente efetivamente são as seguintes:

* App - Nome do aplicativo
* Category - Categoria à qual o aplicativo pertence
* Rating - Classificação geral do aplicativo pelos usuários (como quando foi coletado)
* Reviews - Número de avaliações de usuários para o aplicativo (como quando foi coletado)
* Size - Tamanho do aplicativo (como quando foi coletado)
* Installs - Número de downloads/instalações do aplicativo pelos usuários (como quando foi coletado)
* Type - Pago ou Gratuito
* Price - Preço do aplicativo (como quando foi coletado)
* Content Rating - Faixa etária para a qual o aplicativo é destinada - Crianças / Adultos (21+) / Adulto
* Genres - Um aplicativo pode pertencer a vários gêneros (além de sua categoria principal). Por exemplo, um jogo musical familiar pertencerá
* Last Updated - Última vez que foi atualizado (como quando foi coletado)
* Current Ver - Versão atual (como quando foi coletado)
* Android Ver - Versão do SO suportada (como quando foi coletado)

# 2 - Sanitizando os dados

A sanitização de dados em um dataset é crucial para garantir a qualidade e a confiabilidade das análises e modelos construídos. Este processo envolve identificar e corrigir inconsistências, erros e valores ausentes nos dados, garantindo assim que as conclusões derivadas sejam precisas e não distorcidas por informações incorretas.

Diante disso, tomaremos as devidas medidas para regularizar as variáveis antes de realizarmos análise profunda sob os dados.
"""

#Removendo os NA presentes no dataset
df = df.dropna()

# Removendo duplicados
df = df.drop_duplicates()

# Funções para remover letras de numeros, convertendo string em floats
def convert_size(size):
    if isinstance(size, str):
        if 'M' in size:
            return float(size.replace('M', '')) * 1e6
        elif 'k' in size:
            return float(size.replace('k', '')) * 1e3
        else:
            return np.nan
    return size

def convert_price(price):
    if isinstance(price, str):
        return float(price.replace('$', ''))
    return price


#Aplicando a função de remoção em Installs e price
df['Price'] = df['Price'].apply(convert_price)
df['Installs'] = df['Installs'].str.replace('[+,]', '', regex=True).astype(int)

#Apliando a função de conversão de size, mas como tem opções com texto, converte-se para NA e depois aplica a media aos que ficaram com NA
df['Size'] = df['Size'].replace('Varies with device', np.nan)
df['Size'] = df['Size'].apply(convert_size)
df['Size'] = df['Size'].fillna(df['Size'].median())

#Normalizando a coluna Reviews para int
df['Reviews'] = df['Reviews'].astype(int)

# Analisando como a estrutura ficou após a normalização
print(df.info())

"""# 3 - Descrição dos Dados

Agora que temos os dados consistentes, podemos analisar as variáveis do dataset de maneira robusta, afim de identifcar importantes correlações e relevantes ao problema em tela.
"""

plt.hist(df['Category'])
plt.title('Categorias de Aplicativos')
plt.show()

df.groupby('Category').size()

plt.hist(df['Android Ver'])
plt.xlabel('Versão do Android')
plt.title('Versão do SO')
plt.show()

df.groupby('Android Ver').size()

plt.hist(df['Type'])
plt.xlabel('Tipo de pagamento')
plt.title('Modalidade do App')
plt.show()

plt.hist(df['Content Rating'])
plt.xlabel('Faixa etária')
plt.title('Análise de faixa etária')
plt.show()

plt.boxplot(df['Rating'])
plt.title('Boxplot de Avaliação')
plt.show()

df['Rating'].describe()

"""Notamos o comportamento preciso em termo de avaliações para determinar o nível de popularidade de um aplicativo, portanto cabe uma analise mais aprofundada de outra variável pertinente nesse assunto, o engajamento com as avaliações (variável 'Review')"""

plt.boxplot(df['Reviews'])
plt.title('Boxplot de Engajamento com Avaliação')
plt.show()

df['Reviews'].describe()

"""Há presença de muitos outliers, mas há uma tendência clara concentrando o engajmaneto médio em 5 mil avaliações, logo resultados de pesquisa de aplicativos com esse nivel de engajamento tenderão a refletir a popularidade do app."""

plt.boxplot(df['Installs'])
plt.title('Boxplot de Instalados')
plt.show()

df['Installs'].describe()

"""Por fim, a régua de popularidade que é possível mensurar neste dataset que é o quanto o aplicativo foi instalado/baixado. Importante balizar esta popularidade pelo nível de engajamento pelos usuários. O que faremos a seguir."""

plt.scatter(df['Rating'],df['Reviews'])
plt.xlabel('Nota')
plt.ylabel('Engajamento')
plt.title('Número de Reviews vs Nota dada')
plt.ylim(0, 0.5*1e7)
plt.show()

"""A disperção demonstra que os apps mais bem avaliados tendem a ter o maior engajamento por parte dos usuários, logo este é um bom sinalizador de "sucesso" para um app."""

plt.scatter(df['Price'],df['Installs'])
plt.xlabel('Preço')
plt.ylabel('Instalados')
plt.title('Número de Instalações vs Preço')
plt.ylim(0, 0.5*1e8)
plt.show()

plt.scatter(df['Rating'],df['Installs'])
plt.xlabel('Avaliação')
plt.ylabel('Instalados')
plt.title('Número de Instalações vs Avaliação')
plt.ylim(0, 0.6*1e7)
plt.show()

plt.scatter(df['Installs'], df['Reviews'])
plt.xlabel('Qtde. Avaliações')
plt.ylabel('Instalados')
plt.title('Número de Instalações vs Quantidade de Avaliações')
plt.xlim(0, 0.6*1e7)
plt.ylim(0, 0.6*1e7)
plt.show()

"""Com os elementos acima demonstrados, fica claro que podemos traçar uma variável indicadora do sucesso de um aplicativo, mensurando apartir pela quantidade de instalações, avalaição e engajamento em feedbacks.

# 4 - Criação de Variável

Delimitado os elementos que constituem o sucesso de um app na Play Store, criamos a variável 'succ' que será definida pelos seguintes critérios:

* Número de instalações superiores a 5000
* Avaliação superior a 4.5 estrelas
* Número de avaliações superior a 5000

Esta variável indicará 1 quando atingir esses patamares e 0 quando não. Os patamares foram escolhidos como base na analise de quartis das variáveis, colocando todos no 3o ou 4o quartil de cada uma.
"""

df['succ'] = ((df['Installs'] > 5000) & (df['Rating'] > 4.5) & (df['Reviews'] > 5000)).astype('int64')
print(df.head())

"""A seguir uma pequena análise da distribuição pautando-se pela avaliação dos aplicativos avaliados como sucesso."""

pd.crosstab(df['succ'], df['Rating'])

"""# 5 - Elaborando o modelo

Primeiramente iremos escolher as nossas variáveis qualitativas, que determinarão a variável resposta. Aqui é um reflexo dos elementos estudados anteriormente, logo há consideração também dos elementos constitutivos do aplicativo,
"""

# Selecionando as variáveis qualitativas
df2 = df[['Category', 'Content Rating', 'Type', 'Rating']]
df2.head()

"""Dado o conjunto de variáveis, é feito o passo de inclusão de dummy para poder normalizar as variáveis não numéricas."""

# Adcionando as variáveis dummy para padronizar o estudo
X = pd.get_dummies(df2, drop_first=True)
X.head()

# Determinando a variável resposta
y = df['succ']

# Separando a base e treinando o algoritmo
X_train, X_test, y_train, y_test = train_test_split(X, y)
clf = tree.DecisionTreeClassifier(max_depth = 3)
clf.fit(X_train,y_train)

#Acurácia em treino
acc = accuracy_score(y_train, clf.predict(X_train))
print(f'A acurácia na base de treino é de: {acc:.10%}')

#Matriz de confusão
pd.crosstab(clf.predict(X_train), y_train)

#Acurácia em testes
acc = accuracy_score(y_test, clf.predict(X_test))
print(f'A acurácia na base de teste é de: {acc:.10%}')

#Matriz de confusão
pd.crosstab(clf.predict(X_test), y_test)

# Representação da Árvore de decisão
dot_data = tree.export_graphviz(clf, out_file=None,
                     feature_names=X.columns,
                     class_names=['não', 'sim'],
                     filled=True, rounded=True,
                     special_characters=True)
graph = graphviz.Source(dot_data)
graph

explainer = lime_tabular.LimeTabularExplainer(
    X_train.values,
    feature_names=X.columns,
    class_names=["Insucesso", "Sucesso"])

exp=explainer.explain_instance(X_train.iloc[-1].values, clf.predict_proba)
exp.show_in_notebook()

"""A conclusão do nosso estudo sobre o modelo preditivo evidencia alguns pontos críticos que precisam ser considerados para uma melhor compreensão de seus resultados e implicações. Primeiramente, o modelo alcançou uma acurácia de 90% na base de testes, o que, apesar de ser um valor razoável, ainda indica que há margem para melhorias. Essa performance sugere que o modelo é competente em suas previsões, mas não perfeito, e ainda comete erros em 10% dos casos.

Além disso, é importante destacar a significativa variabilidade entre os elementos da variável predita. Essa variação indica que a distribuição dos dados não é homogênea e que diferentes segmentos da população analisada podem estar influenciando de maneira desigual o desempenho do modelo. Portanto, uma análise mais detalhada sobre a origem dessa variabilidade é essencial para entender se o modelo está capturando todas as nuances dos dados ou se há grupos específicos onde a performance é inferior.

Por fim, é imperativo refletir sobre o objetivo do problema para avaliar se a acurácia alcançada é suficiente. Dependendo do contexto e da aplicação do modelo, uma acurácia de 90% pode ser considerada satisfatória ou insuficiente. Para aplicações críticas, onde erros podem ter consequências severas, esse nível de acurácia pode não ser aceitável. Portanto, é necessário ponderar os requisitos do problema em questão e decidir se o modelo atual atende a essas necessidades ou se são necessárias melhorias adicionais para alcançar um desempenho mais robusto e confiável.

Em resumo, apesar do modelo apresentar uma acurácia de 90%, a variabilidade entre os elementos da variável e a importância do objetivo do problema sugerem que uma análise mais aprofundada e possíveis ajustes são necessários para garantir que o modelo seja verdadeiramente eficaz e adequado para o uso pretendido.
"""